ğŸ“Œ Replit Prompt â€” Refactor MetaLingua Placement Test to MST (10-minute, 4-skill), Remove Legacy Code
0) Context & Constraints
Product: MetaLingua 4-skill placement test (Listening, Reading, Speaking, Writing).
Target duration: 10 minutes total; 2.5 minutes per skill (hard cap).
Adaptive method: Multistage Testing (MST) with two stages per skill: S1 Core (B1), route UP (B2/C1) or DOWN (A2/B1-), or STAY (Core-2).
Self-hosted only.
No external dependencies except:
Microsoft Edge TTS (already allowed).
Whisper (already implemented on our side) for ASR.
Available LLMs: Llama 3.2 and Mistral (locally hosted).
Remove all unused / legacy code from the previous placement module.
1) Objectives
Replace the current placement workflow with the MST design.
Guarantee fixed per-skill time budget and auto-advance.
Implement fast â€œquickscoreâ€ for each skill:
L/R: fully auto-scorable (MCQ/short answer).
S/W: heuristic feature-based scoring (no new libs) + optional LLM tier for tie-break only.
Provide routing (UP/DOWN/STAY) after S1 within â‰¤200 ms server time.
Clean the codebase: remove dead endpoints, components, assets not used by the MST flow.
2) Deliverables
Updated API (endpoints listed below).
Updated front-end (timers, UI states, auto-flow).
Item bank JSON schemas & loaders.
Quickscore engine per skill (no external ML deps).
Routing logic (heuristic now; swappable to Bayesian later).
Telemetry/logging for audit.
Comprehensive cleanup PR removing legacy code.
3) Information Architecture & Files
Suggested structure (adapt to our repo):

/server
  /modules/mst
    itemBank/
      listening/*.json
      reading/*.json
      speaking/*.json
      writing/*.json
    scorers/
      listeningQuickscore.js
      readingQuickscore.js
      speakingQuickscore.js
      writingQuickscore.js
    routing/
      router.js         // UP/DOWN/STAY
    services/
      ttsEdge.js        // Microsoft Edge TTS wrapper
      asrWhisper.js     // Whisper wrapper (already present: refactor only)
    controllers/
      itemsController.js
      responsesController.js
      sessionController.js
    schemas/
      itemSchema.ts     // TS or JS typedefs
      resultSchema.ts
    utils/
      timers.js
      textStats.js      // TTR, error density (basic regex/POS-approx)
      audioUtils.js     // VAD hooks if present
  /legacy/              // TEMP staging for files to delete in this PR
/client
  /mst
    pages/
      Listening.vue|tsx
      Reading.vue|tsx
      Speaking.vue|tsx
      Writing.vue|tsx
    components/
      Countdown.tsx
      Waveform.tsx
      RecordButton.tsx (disabled; auto only)
      McqBlock.tsx
      PassagePane.tsx
      PromptPane.tsx
4) Item Bank JSON (one example per skill)
Use this schema (extend as needed):

{
  "id": "L-B1-034",
  "skill": "listening",
  "stage": "core",         // core | upper | lower
  "cefr": "B1",
  "assets": { "audio": "/assets/l/L-B1-034.mp3", "transcript": "..." },
  "timing": { "audioSec": 32, "maxAnswerSec": 40 },
  "questions": [
    {
      "type": "mcq_single",
      "stem": "Why did the speaker miss the train?",
      "options": ["Traffic", "Overslept", "Wrong ticket", "Line closure"],
      "answerIndex": 1
    }
  ],
  "metadata": { "accent": "genAm", "domain": "social" }
}
Create parallel schemas for reading (passage text), speaking (prompt string), writing (prompt + word target).
5) API Endpoints (minimal)
POST /mst/start â†’ returns { skillOrder: ["L","R","S","W"], perSkillSeconds:150 }
GET /mst/item?skill=L&stage=core â†’ returns item JSON
POST /mst/response â†’ payload { sessionId, skill, stage, itemId, data }
L/R: {answers:[0|1|...], latencyMs:number}
S: {audioUrl, asr={text, conf}} (server can call Whisper if only audioUrl provided)
W: {text}
POST /mst/quickscore â†’ returns { p: number(0..1), route: "up"|"down"|"stay" }
POST /mst/finalize â†’ returns per-skill { band:"A2/B1/B2/C1", confidence:0..1 } and overall suggestion.
6) MST Routing (implement now; pluggable later)
Heuristic routing for S1:
If p >= 0.75 â†’ UP (Upper stage)
If p < 0.45 â†’ DOWN (Lower stage)
Else â†’ STAY (Core-2)â€¨Final band = S2 stage level, annotate with â€œ+â€ if p >= 0.8, â€œâ€“â€ if p <= 0.5.
Pseudocode (server/modules/mst/routing/router.js):

export function route(p) {
  if (p >= 0.75) return "up";
  if (p < 0.45)  return "down";
  return "stay";
}
7) Quickscore Engines (no external deps)
Listening
Score MCQ: 1 correct = 1.0 else 0.0; for 2 questions use mean.
Penalize extreme slow answers: if answerLatencyMs > 95th percentile of target, p -= 0.1 (min 0).
Reading
Same MCQ logic; for multi-select allow partial credit: p = max(0, (#correct/#keys) - (#wrong/#options)*0.5).
Speaking (use Whisper â†’ text + timing)
Inputs: transcript, tokens, silenceMs, durationSec.
Features (all implementable with basic JS/TS):
Fluency (0.30): words per minute (110â€“170 optimal), silence ratio < 0.2, filled pauses per 10s.
Lexical (0.25): typeâ€“token ratio; proportion of B-band words from an internal frequency list (ship a tiny JSON frequency map).
Grammar (0.25): error density proxy via simple rules (e.g., common verb-tense errors regex, subject-verb mismatch patterns, sentence boundary checks).
Tasking (0.20): presence of structure markers (intro phrase + â‰¥1 â€œbecause/for example/firstlyâ€).
Combine to p âˆˆ [0,1]. Cap compute â‰¤150 ms.
Writing
Inputs: text.
Features:
Task (0.25): stance present + 2 reasons keywords + example (Upper only).
Coherence (0.25): discourse markers count normalized by length.
Grammar (0.25): simple spell/error ratio (built-in dictionary or basic regex misspell counts) + clause-per-sentence variety proxy.
Lexical (0.25): typeâ€“token ratio; low-freq word ratio via the same frequency map.
Compute p quickly (<150 ms).
Important: Keep the LLM scoring path optional (see Section 10). Default path must be heuristic only to guarantee latency.
8) Front-end UX (per skill)
Single screen with:
Visible countdown (150s total skill budget).
S1 item first. On submit â†’ call /mst/quickscore â†’ route â†’ auto-fetch S2.
Auto-advance to next skill at time-up or after S2 submit.
Speaking:
Auto-start mic after 10s prep; auto-stop at 35â€“45s.
Show waveform + countdown; no manual pause/retry.
Writing:
Word counter with soft minimum; no grammar corrector.
9) Timing Guards (strict)
Global per-skill 150s cap (server-enforced).
Listening audio capped at 40s; Reading passage 80â€“180 words as per stage.
Speaking record 30â€“40s; Writing compose 80â€“90s.
10) Optional LLM Tier (tie-break only)
If local Llama 3.2 / Mistral inference is available without blocking, allow tie-break on S/W when 0.45 < p < 0.55:
Prompt the LLM with rubric + transcript/text for a binary nudge (up/down) only.
Hard timeout 300 ms; if exceeded, skip and keep heuristic result.
Do not send all responses to LLM in real time; only ambiguous cases.
11) Telemetry & Audit
Log per item: {userId, skill, stage, itemId, p, route, timeSpentMs}.
Store artifacts: Listening/Reading answers, Speaking audio + Whisper transcript, Writing text.
Export final: per-skill band + overall band + confidence.

12) Acceptance Criteria
End-to-end run completes in â‰¤10 minutes under normal use.
Each skill enforces 150s cap; auto-advance works.
S1â†’S2 routing decision in â‰¤200 ms.
Heuristic quickscore for S/W computes in â‰¤150 ms per response.
No external runtime deps beyond Edge TTS & Whisper.
Legacy code paths removed; repository builds clean.
Load test: 1,000 concurrent users on a single node must keep median S1 routing â‰¤250 ms (S/W scored heuristically).
13) Test Plan
Unit tests for scorers (inputâ†’p), router, timers.
Integration tests for /mst endpoints.
Manual QA with 6 sample sessions (A2/B1/B2 paths).
Load test with k6/locust (if available) or a simple in-house script.
